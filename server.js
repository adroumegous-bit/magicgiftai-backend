"use strict";

const PROMPT_VERSION = "v4.2-2025-12-30";

const express = require("express");
const cors = require("cors");
require("dotenv").config();

const app = express();

app.use(cors());
app.use(express.json({ limit: "1mb" }));

// Logs safe (aprÃ¨s dÃ©claration)
console.log("PROMPT_VERSION:", PROMPT_VERSION);
console.log("OPENAI key loaded:", (process.env.OPENAI_API_KEY || "").slice(0, 12) + "...");
console.log("PORT env:", process.env.PORT);

// --- Util: extraire du texte proprement depuis Responses API ---
function extractOutputText(data) {
  if (typeof data?.output_text === "string" && data.output_text.trim()) {
    return data.output_text.trim();
  }

  const chunks =
    data?.output
      ?.flatMap((o) => o?.content || [])
      ?.map((c) => c?.text)
      ?.filter((t) => typeof t === "string" && t.trim().length > 0) || [];

  return chunks.join("\n").trim();
}

// âœ… Prompt maÃ®tre (SYSTEM)
const systemPrompt = `
Tu es MagicGiftAI, un assistant spÃ©cialisÃ© dans le choix de cadeaux.
Ton rÃ´le : faire dÃ©cider vite et bien avec des recommandations concrÃ¨tes, rÃ©alistes, actionnables.
Tu nâ€™es pas un gÃ©nÃ©rateur dâ€™idÃ©es : tu es un coach de dÃ©cision.

LANGUE & STYLE
- FranÃ§ais.
- Ton humain, naturel, un peu fun, jamais robot.
- Phrases courtes. Fluide. Comme un pote compÃ©tent.
- Ã€ chaque rÃ©ponse, tu ajoutes une mini-phrase rassurante : â€œOn fait simple.â€ / â€œJe te guide.â€ / â€œTu ne peux pas te planter.â€

INTERDICTION FORMELLE (TRÃˆS IMPORTANT)
- Interdit dâ€™Ã©crire : â€œIdÃ©e 1â€, â€œIdÃ©e 2â€, â€œOption 1â€, â€œOption A/Bâ€, ou toute numÃ©rotation.
- Interdit de faire une liste Ã  puces, ou un format â€œficheâ€ (ðŸŽâœ…âš ï¸ðŸ…±ï¸â±ï¸).
- Interdit dâ€™aligner des champs (â€œPourquoi:â€, â€œRisque:â€, etc.).
=> Tu Ã©cris UNIQUEMENT en conversation, en 2 Ã  5 paragraphes max.

RÃˆGLES
- Par dÃ©faut : propose 2 pistes max. 3 uniquement si nÃ©cessaire.
- Jamais dâ€™idÃ©es vagues (â€œun parfumâ€, â€œun bijouâ€) sans exemple concret achetable.
- Maximum 2 questions par message, seulement si Ã§a aide Ã  dÃ©cider.
- Si infos floues : tu poses 1 question max ET tu proposes quand mÃªme 2 pistes avec hypothÃ¨ses brÃ¨ves.
- Tu tranches toujours clairement : une recommandation finale (â€œJe te conseille X.â€) + une raison en 1 phrase.
- Tu finis toujours par UNE question dâ€™action simple (choix immÃ©diat).

MODE EXPRESS (automatique si urgence / message court)
- 1 ou 2 pistes max
- justification ultra courte
- tu tranches
- question dâ€™action immÃ©diate

SCORING
- Tu gardes un scoring en interne.
- Tu nâ€™affiches le scoring QUE si lâ€™utilisateur le demande explicitement (score/note/classement/comparatif).
- Si scoring demandÃ© : tu donnes une mini-comparaison compacte sur une seule ligne, sans tableau, sans listes.
- Si lâ€™utilisateur demande un scoring mais ne redonne pas les 2 options (et que tu ne les as pas dans le message), tu lui demandes de les coller. 1 question max.

GESTION â€œpas convaincuâ€
- Tu dis : â€œOK, Ã§a ne matche pas.â€
- 1 cause probable max
- tu changes dâ€™axe (objetâ†’expÃ©rience, utileâ†’Ã©motion, etc.)
- tu proposes 2 nouvelles pistes
- question dâ€™action

CLÃ”TURE
Si lâ€™utilisateur dit quâ€™il a choisi : tu clos chaleureusement, sans relancer, sans nouvelle idÃ©e, sans question.
`.trim();

// 1) Healthcheck
app.get("/health", (req, res) => {
  res.json({
    ok: true,
    service: "MagicGiftAI backend",
    time: new Date().toISOString(),
    promptVersion: PROMPT_VERSION,
  });
});

// 2) Home
app.get("/", (req, res) => {
  res.json({ status: "ok", service: "MagicGiftAI backend running" });
});

// 3) Chat endpoint
app.post("/chat", async (req, res) => {
  try {
    const userMessage = (req.body?.message || "").trim();
    if (!userMessage) return res.status(400).json({ ok: false, error: "Missing 'message' in body" });

    if (!process.env.OPENAI_API_KEY) {
      return res.status(500).json({ ok: false, error: "OPENAI_API_KEY is not set in env" });
    }

    const r = await fetch("https://api.openai.com/v1/responses", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-4.1-mini",
        input: [
          { role: "system", content: [{ type: "input_text", text: systemPrompt }] },
          { role: "user", content: [{ type: "input_text", text: userMessage }] },
        ],
        max_output_tokens: 650,
      }),
    });

    const data = await r.json();
    if (!r.ok) return res.status(500).json({ ok: false, error: data, promptVersion: PROMPT_VERSION });

    const answer = extractOutputText(data);

    if (!answer) {
      return res.status(500).json({
        ok: false,
        error: "Empty answer from OpenAI (try again / check prompt & model).",
        raw: data?.id || null,
        promptVersion: PROMPT_VERSION,
      });
    }

    // Nettoyage lÃ©ger pour affichage (au cas oÃ¹)
    const clean = String(answer)
      .replace(/\\n/g, "\n")
      .replace(/\u00a0/g, " ")
      .trim();

    return res.json({ ok: true, answer: clean, promptVersion: PROMPT_VERSION });
  } catch (err) {
    return res.status(500).json({ ok: false, error: err?.message || String(err), promptVersion: PROMPT_VERSION });
  }
});

const PORT = Number(process.env.PORT || 3000);
app.listen(PORT, () => console.log(`Server running on port ${PORT}`));
